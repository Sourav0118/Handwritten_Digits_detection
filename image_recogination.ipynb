{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e6da1e6",
   "metadata": {},
   "source": [
    "# Image Recogination using Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6054a309",
   "metadata": {},
   "source": [
    "## Exporting the data\n",
    "#### we begin by importing torch and torchvision.  torchvision contains some utilities for working with image data. it alos contains the helper classes to automatically dowmload and import popular dataset like MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "224faa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torchvision.transforms as trn\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10fd21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root = \"/media/souravsaini/Data/POP_OS/dl/pytorch/pytorch\", download = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ca32ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07553159",
   "metadata": {},
   "source": [
    "the dataset has 60,000 images which can be used to train the model. there is also an aditional test set of 10,000 images which can be created by passing train=False to the MNIST class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2024ca46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = MNIST(root = \"/media/souravsaini/Data/POP_OS/dl/pytorch/pytorch\", train = False)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ede71f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28>, 5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48abc9c8",
   "metadata": {},
   "source": [
    "it's a pair consiting of a 28x28 image and a lable. the image is an object of the class PIL.Image.Image, which is a part of the python imaging library Piloow. we can view the image within jupyter matlpotlib, the de-facto lpotting and graphing library for the data science in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81270997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaTElEQVR4nO3de0zV9/3H8dfBy/FSOA4RDlRU1FY3b8ucIrF17WQCW4y3LNr5h25Go8Nm6noZ26p13UKnSdu4OLstja5Zta3b1GkWEosFsw1stBpj7IgYWjAKtiacoyho4PP7w1/PPBW0B8/hzYHnI/kk5ZzvB9797tTnvnD84nHOOQEA0MUSrAcAAPROBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjoaz3AF7W1tenixYtKTEyUx+OxHgcAECHnnK5evaqMjAwlJHR8ndPtAnTx4kVlZmZajwEAeEB1dXUaPnx4h893u2/BJSYmWo8AAIiC+/15HrMAbd++XaNGjdKAAQOUnZ2tDz744Evt49tuANAz3O/P85gE6J133tGGDRu0adMmffjhh5oyZYry8vJ0+fLlWHw5AEA8cjEwffp0V1hYGPq4tbXVZWRkuOLi4vvuDQQCThKLxWKx4nwFAoF7/nkf9Sugmzdv6sSJE8rNzQ09lpCQoNzcXFVUVNx1fEtLi4LBYNgCAPR8UQ/QZ599ptbWVqWlpYU9npaWpvr6+ruOLy4uls/nCy3eAQcAvYP5u+CKiooUCARCq66uznokAEAXiPrfA0pJSVGfPn3U0NAQ9nhDQ4P8fv9dx3u9Xnm93miPAQDo5qJ+BdS/f39NnTpVpaWlocfa2tpUWlqqnJycaH85AECcismdEDZs2KBly5bpm9/8pqZPn67XXntNTU1N+uEPfxiLLwcAiEMxCdDixYv16aefauPGjaqvr9fXv/51lZSU3PXGBABA7+VxzjnrIe4UDAbl8/msxwAAPKBAIKCkpKQOnzd/FxwAoHciQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATPS1HgBAz1BUVBTxnt/85jcR79myZUvEe372s59FvAexxxUQAMAEAQIAmIh6gF588UV5PJ6wNX78+Gh/GQBAnIvJz4AmTJig9957739fpC8/agIAhItJGfr27Su/3x+LTw0A6CFi8jOgc+fOKSMjQ6NHj9bSpUtVW1vb4bEtLS0KBoNhCwDQ80U9QNnZ2dq1a5dKSkq0Y8cO1dTU6PHHH9fVq1fbPb64uFg+ny+0MjMzoz0SAKAbinqACgoK9P3vf1+TJ09WXl6e/vnPf6qxsVHvvvtuu8cXFRUpEAiEVl1dXbRHAgB0QzF/d8CQIUP06KOPqrq6ut3nvV6vvF5vrMcAAHQzMf97QNeuXdP58+eVnp4e6y8FAIgjUQ/QM888o/Lycn388cf6z3/+owULFqhPnz566qmnov2lAABxLOrfgrtw4YKeeuopXblyRcOGDdNjjz2myspKDRs2LNpfCgAQxzzOOWc9xJ2CwaB8Pp/1GECvlpiYGPGeqqqqiPekpaVFvOfWrVsR7yksLIx4jyS98cYbndqH2wKBgJKSkjp8nnvBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmYv4L6QDY6du3c/+Jr1mzJuI9nbmxaGc0NDREvKeioiIGk+BBcQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9wNG+jBZsyY0al9xcXFUZ4kelavXh3xnrNnz8ZgEjworoAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBSIE6NGjYp4z7Zt26I/SBSVlpZGvKesrCz6g8AEV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRgrEiYMHD0a852tf+1oMJmlfMBiMeM/WrVsj3nPjxo2I96B74goIAGCCAAEATEQcoKNHj2ru3LnKyMiQx+PR/v37w553zmnjxo1KT0/XwIEDlZubq3PnzkVrXgBADxFxgJqamjRlyhRt37693ee3bNmibdu26fXXX9exY8c0ePBg5eXlqbm5+YGHBQD0HBG/CaGgoEAFBQXtPuec02uvvaZf/vKXmjdvniTpzTffVFpamvbv368lS5Y82LQAgB4jqj8DqqmpUX19vXJzc0OP+Xw+ZWdnq6Kiot09LS0tCgaDYQsA0PNFNUD19fWSpLS0tLDH09LSQs99UXFxsXw+X2hlZmZGcyQAQDdl/i64oqIiBQKB0Kqrq7MeCQDQBaIaIL/fL0lqaGgIe7yhoSH03Bd5vV4lJSWFLQBAzxfVAGVlZcnv96u0tDT0WDAY1LFjx5STkxPNLwUAiHMRvwvu2rVrqq6uDn1cU1OjU6dOKTk5WSNGjNC6dev061//Wo888oiysrL0wgsvKCMjQ/Pnz4/m3ACAOBdxgI4fP64nn3wy9PGGDRskScuWLdOuXbv03HPPqampSatWrVJjY6Mee+wxlZSUaMCAAdGbGgAQ9zzOOWc9xJ2CwaB8Pp/1GEC309bWFvGervzP++WXX454zy9+8YsYTILuIhAI3PPn+ubvggMA9E4ECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwEfGvYwDw4F555ZWI93g8noj3dPZu2Hf+Uskv66WXXurU10LvxRUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5ECD2j79u0R75k/f37EezpzY9HTp09HvEeSli5dGvGe5ubmTn0t9F5cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKXCH6dOnR7ynMzcW9fv9Ee/pjD/+8Y+d2vfpp59GeRLgblwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpcIcf/ehHEe9JT0+PwSR3++ijjyLec+DAgRhMAkQHV0AAABMECABgIuIAHT16VHPnzlVGRoY8Ho/2798f9vzy5cvl8XjCVn5+frTmBQD0EBEHqKmpSVOmTNH27ds7PCY/P1+XLl0KrT179jzQkACAnifiNyEUFBSooKDgnsd4vd4u+42PAID4FJOfAZWVlSk1NVXjxo3TmjVrdOXKlQ6PbWlpUTAYDFsAgJ4v6gHKz8/Xm2++qdLSUv32t79VeXm5CgoK1Nra2u7xxcXF8vl8oZWZmRntkQAA3VDU/x7QkiVLQv88adIkTZ48WWPGjFFZWZlmz5591/FFRUXasGFD6ONgMEiEAKAXiPnbsEePHq2UlBRVV1e3+7zX61VSUlLYAgD0fDEP0IULF3TlypUu+9viAID4EPG34K5duxZ2NVNTU6NTp04pOTlZycnJ2rx5sxYtWiS/36/z58/rueee09ixY5WXlxfVwQEA8S3iAB0/flxPPvlk6OPPf36zbNky7dixQ6dPn9af//xnNTY2KiMjQ3PmzNFLL70kr9cbvakBAHHP45xz1kPcKRgMyufzWY+BOLdu3bpO7du6dWvEexISuuaOVp15c87FixdjMAnw5QQCgXv+XJ97wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBE1H8lNxBtnbkL9IoVKzr1tTpzZ+vW1taI9/zpT3+KeA93tkZPwxUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5GiS40dOzbiPf/4xz8i3jNu3LiI93TWq6++GvGe559/PgaTAPGFKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3I0WX6sxNQrvyxqKd0ZmbpQLgCggAYIQAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSNGlkpOTrUe4p7Kysoj3nD17NvqDAL0AV0AAABMECABgIqIAFRcXa9q0aUpMTFRqaqrmz5+vqqqqsGOam5tVWFiooUOH6qGHHtKiRYvU0NAQ1aEBAPEvogCVl5ersLBQlZWVOnz4sG7duqU5c+aoqakpdMz69et18OBB7d27V+Xl5bp48aIWLlwY9cEBAPEtojchlJSUhH28a9cupaam6sSJE5o1a5YCgYDeeOMN7d69W9/+9rclSTt37tRXv/pVVVZWasaMGdGbHAAQ1x7oZ0CBQEDS/97ZdOLECd26dUu5ubmhY8aPH68RI0aooqKi3c/R0tKiYDAYtgAAPV+nA9TW1qZ169Zp5syZmjhxoiSpvr5e/fv315AhQ8KOTUtLU319fbufp7i4WD6fL7QyMzM7OxIAII50OkCFhYU6c+aM3n777QcaoKioSIFAILTq6uoe6PMBAOJDp/4i6tq1a3Xo0CEdPXpUw4cPDz3u9/t18+ZNNTY2hl0FNTQ0yO/3t/u5vF6vvF5vZ8YAAMSxiK6AnHNau3at9u3bpyNHjigrKyvs+alTp6pfv34qLS0NPVZVVaXa2lrl5OREZ2IAQI8Q0RVQYWGhdu/erQMHDigxMTH0cx2fz6eBAwfK5/NpxYoV2rBhg5KTk5WUlKSnn35aOTk5vAMOABAmogDt2LFDkvTEE0+EPb5z504tX75ckvTqq68qISFBixYtUktLi/Ly8vT73/8+KsMCAHoOj3POWQ9xp2AwKJ/PZz0GYuTjjz+OeE9XvjNy8eLFEe/561//GoNJgPgXCASUlJTU4fPcCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmOvUbUQFJmjBhQsR7Bg8eHINJ7rZ58+ZO7fvb3/4W5UkAdIQrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjRafNmDEj4j2JiYkxmORuLS0tndrnnIvyJAA6whUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC47rZ3ReDwaB8Pp/1GIiRTz75JOI9gwYNinjPd77znYj3SNKpU6c6tQ/A3QKBgJKSkjp8nisgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEX+sB0LuMHDnSegQA3QRXQAAAEwQIAGAiogAVFxdr2rRpSkxMVGpqqubPn6+qqqqwY5544gl5PJ6wtXr16qgODQCIfxEFqLy8XIWFhaqsrNThw4d169YtzZkzR01NTWHHrVy5UpcuXQqtLVu2RHVoAED8i+hNCCUlJWEf79q1S6mpqTpx4oRmzZoVenzQoEHy+/3RmRAA0CM90M+AAoGAJCk5OTns8bfeekspKSmaOHGiioqKdP369Q4/R0tLi4LBYNgCAPQCrpNaW1vd9773PTdz5sywx//whz+4kpISd/r0afeXv/zFPfzww27BggUdfp5NmzY5SSwWi8XqYSsQCNyzI50O0OrVq93IkSNdXV3dPY8rLS11klx1dXW7zzc3N7tAIBBadXV15ieNxWKxWA++7hegTv1F1LVr1+rQoUM6evSohg8ffs9js7OzJUnV1dUaM2bMXc97vV55vd7OjAEAiGMRBcg5p6efflr79u1TWVmZsrKy7rvn1KlTkqT09PRODQgA6JkiClBhYaF2796tAwcOKDExUfX19ZIkn8+ngQMH6vz589q9e7e++93vaujQoTp9+rTWr1+vWbNmafLkyTH5FwAAxKlIfu6jDr7Pt3PnTuecc7W1tW7WrFkuOTnZeb1eN3bsWPfss8/e9/uAdwoEAubft2SxWCzWg6/7/dnv+f+wdBvBYFA+n896DADAAwoEAkpKSurwee4FBwAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAw0e0C5JyzHgEAEAX3+/O82wXo6tWr1iMAAKLgfn+ee1w3u+Roa2vTxYsXlZiYKI/HE/ZcMBhUZmam6urqlJSUZDShPc7DbZyH2zgPt3EebusO58E5p6tXryojI0MJCR1f5/Ttwpm+lISEBA0fPvyexyQlJfXqF9jnOA+3cR5u4zzcxnm4zfo8+Hy++x7T7b4FBwDoHQgQAMBEXAXI6/Vq06ZN8nq91qOY4jzcxnm4jfNwG+fhtng6D93uTQgAgN4hrq6AAAA9BwECAJggQAAAEwQIAGAibgK0fft2jRo1SgMGDFB2drY++OAD65G63IsvviiPxxO2xo8fbz1WzB09elRz585VRkaGPB6P9u/fH/a8c04bN25Uenq6Bg4cqNzcXJ07d85m2Bi633lYvnz5Xa+P/Px8m2FjpLi4WNOmTVNiYqJSU1M1f/58VVVVhR3T3NyswsJCDR06VA899JAWLVqkhoYGo4lj48uchyeeeOKu18Pq1auNJm5fXATonXfe0YYNG7Rp0yZ9+OGHmjJlivLy8nT58mXr0brchAkTdOnSpdD617/+ZT1SzDU1NWnKlCnavn17u89v2bJF27Zt0+uvv65jx45p8ODBysvLU3NzcxdPGlv3Ow+SlJ+fH/b62LNnTxdOGHvl5eUqLCxUZWWlDh8+rFu3bmnOnDlqamoKHbN+/XodPHhQe/fuVXl5uS5evKiFCxcaTh19X+Y8SNLKlSvDXg9btmwxmrgDLg5Mnz7dFRYWhj5ubW11GRkZrri42HCqrrdp0yY3ZcoU6zFMSXL79u0LfdzW1ub8fr/bunVr6LHGxkbn9Xrdnj17DCbsGl88D845t2zZMjdv3jyTeaxcvnzZSXLl5eXOudv/2/fr18/t3bs3dMxHH33kJLmKigqrMWPui+fBOee+9a1vuZ/85Cd2Q30J3f4K6ObNmzpx4oRyc3NDjyUkJCg3N1cVFRWGk9k4d+6cMjIyNHr0aC1dulS1tbXWI5mqqalRfX192OvD5/MpOzu7V74+ysrKlJqaqnHjxmnNmjW6cuWK9UgxFQgEJEnJycmSpBMnTujWrVthr4fx48drxIgRPfr18MXz8Lm33npLKSkpmjhxooqKinT9+nWL8TrU7W5G+kWfffaZWltblZaWFvZ4Wlqa/vvf/xpNZSM7O1u7du3SuHHjdOnSJW3evFmPP/64zpw5o8TEROvxTNTX10tSu6+Pz5/rLfLz87Vw4UJlZWXp/Pnz+vnPf66CggJVVFSoT58+1uNFXVtbm9atW6eZM2dq4sSJkm6/Hvr3768hQ4aEHduTXw/tnQdJ+sEPfqCRI0cqIyNDp0+f1vPPP6+qqir9/e9/N5w2XLcPEP6noKAg9M+TJ09Wdna2Ro4cqXfffVcrVqwwnAzdwZIlS0L/PGnSJE2ePFljxoxRWVmZZs+ebThZbBQWFurMmTO94ueg99LReVi1alXonydNmqT09HTNnj1b58+f15gxY7p6zHZ1+2/BpaSkqE+fPne9i6WhoUF+v99oqu5hyJAhevTRR1VdXW09ipnPXwO8Pu42evRopaSk9MjXx9q1a3Xo0CG9//77Yb++xe/36+bNm2psbAw7vqe+Hjo6D+3Jzs6WpG71euj2Aerfv7+mTp2q0tLS0GNtbW0qLS1VTk6O4WT2rl27pvPnzys9Pd16FDNZWVny+/1hr49gMKhjx471+tfHhQsXdOXKlR71+nDOae3atdq3b5+OHDmirKyssOenTp2qfv36hb0eqqqqVFtb26NeD/c7D+05deqUJHWv14P1uyC+jLffftt5vV63a9cud/bsWbdq1So3ZMgQV19fbz1al/rpT3/qysrKXE1Njfv3v//tcnNzXUpKirt8+bL1aDF19epVd/LkSXfy5Eknyb3yyivu5MmT7pNPPnHOOffyyy+7IUOGuAMHDrjTp0+7efPmuaysLHfjxg3jyaPrXufh6tWr7plnnnEVFRWupqbGvffee+4b3/iGe+SRR1xzc7P16FGzZs0a5/P5XFlZmbt06VJoXb9+PXTM6tWr3YgRI9yRI0fc8ePHXU5OjsvJyTGcOvrudx6qq6vdr371K3f8+HFXU1PjDhw44EaPHu1mzZplPHm4uAiQc8797ne/cyNGjHD9+/d306dPd5WVldYjdbnFixe79PR0179/f/fwww+7xYsXu+rqauuxYu799993ku5ay5Ytc87dfiv2Cy+84NLS0pzX63WzZ892VVVVtkPHwL3Ow/Xr192cOXPcsGHDXL9+/dzIkSPdypUre9z/SWvv31+S27lzZ+iYGzduuB//+MfuK1/5ihs0aJBbsGCBu3Tpkt3QMXC/81BbW+tmzZrlkpOTndfrdWPHjnXPPvusCwQCtoN/Ab+OAQBgotv/DAgA0DMRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACb+DyHNVyVpV0gwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[23]\n",
    "plt.imshow(image, cmap='gray')  #cmap = \"gray\" tells that image is combinations of shades of grey\n",
    "print(\"label: \", label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b342a66",
   "metadata": {},
   "source": [
    "## Convert images to pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7bd4d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "dataset = MNIST(root = \"/media/souravsaini/Data/POP_OS/dl/pytorch/pytorch\", train=True, transform = trn.ToTensor())\n",
    "img_t, label = dataset[0]\n",
    "print(img_t.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b37ea91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
      "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
      "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
      "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
      "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
      "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
      "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
      "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
      "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
      "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
      "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
      "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
      "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(img_t[0:, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5cd7e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2c34923700>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAARu0lEQVR4nO3dX2iVh/3H8W/U5ehsEmo77ULiWtbR4SSOai2hsHY1q0iR9m4XhQYHwkYylNyM3Ex2MeLVaLeKk/3rLuZ0G6SFjtaJnYZBXWMkYDta6OhFhtOsFzuJgZ265PwufpDfXFt/OTHfPOfE1wuei3N40ufDKeTNOU8Sm6rVajUAYImtKnoAACuTwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0CKNct9wbm5ubh8+XK0tLREU1PTcl8egFtQrVZjeno62tvbY9Wqm79HWfbAXL58OTo7O5f7sgAsoYmJiejo6LjpOcsemJaWluW+ZMP64Q9/WPSEhtDb21v0hIawf//+oic0hN/85jdFT2gIC/levuyB+c+PxXxEdnPr1q0rekJDaG1tLXpCQ/jUpz5V9ARWkIV8/3aTH4AUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIsajAHDlyJO69995Yu3ZtPPzww/Hmm28u9S4AGlzNgTl58mQMDAzEoUOH4uLFi7Ft27bYvXt3TE5OZuwDoEHVHJgf/OAHsX///ti3b19s2bIlfvzjH8enP/3p+PnPf56xD4AGVVNgPvzwwxgbG4uenp7/+w+sWhU9PT3xxhtvLPk4ABrXmlpO/uCDD2J2djY2bdp0w/ObNm2Kd95552O/plKpRKVSmX88NTW1iJkANJr0nyIbGhqKtra2+aOzszP7kgDUgZoCc/fdd8fq1avj6tWrNzx/9erVuOeeez72awYHB6NcLs8fExMTi18LQMOoKTDNzc2xffv2OHPmzPxzc3NzcebMmeju7v7YrymVStHa2nrDAcDKV9M9mIiIgYGB6O3tjR07dsTOnTvjueeei5mZmdi3b1/GPgAaVM2B+frXvx7/+Mc/4rvf/W5cuXIlvvzlL8drr732kRv/ANzeag5MRER/f3/09/cv9RYAVhB/iwyAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKRYU+TFq9VqkZeve+VyuegJrCD79+8vekJD+PWvf130hLpWrVYX/L3bOxgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApKg5MCMjI7F3795ob2+PpqameOmllxJmAdDoag7MzMxMbNu2LY4cOZKxB4AVYk2tX7Bnz57Ys2dPxhYAVhD3YABIUfM7mFpVKpWoVCrzj6emprIvCUAdSH8HMzQ0FG1tbfNHZ2dn9iUBqAPpgRkcHIxyuTx/TExMZF8SgDqQ/hFZqVSKUqmUfRkA6kzNgbl27Vq8995784/ff//9GB8fjw0bNsTmzZuXdBwAjavmwFy4cCG++tWvzj8eGBiIiIje3t548cUXl2wYAI2t5sA89thjUa1WM7YAsIL4PRgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJCiqVqtVpfzglNTU9HW1racl2xY69evL3pCQ/j9739f9ISG8OijjxY9oSHs3r276Al17d///ne8/vrrUS6Xo7W19abnegcDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQ1BWZoaCgeeuihaGlpiY0bN8bTTz8d7777btY2ABpYTYE5d+5c9PX1xfnz5+P06dNx/fr1eOKJJ2JmZiZrHwANak0tJ7/22ms3PH7xxRdj48aNMTY2Fl/5yleWdBgAja2mwPy3crkcEREbNmz4xHMqlUpUKpX5x1NTU7dySQAaxKJv8s/NzcXBgwfjkUceia1bt37ieUNDQ9HW1jZ/dHZ2LvaSADSQRQemr68v3nrrrThx4sRNzxscHIxyuTx/TExMLPaSADSQRX1E1t/fH6+88kqMjIxER0fHTc8tlUpRKpUWNQ6AxlVTYKrVanz729+O4eHhOHv2bNx3331ZuwBocDUFpq+vL44fPx4vv/xytLS0xJUrVyIioq2tLdatW5cyEIDGVNM9mKNHj0a5XI7HHnssPvvZz84fJ0+ezNoHQIOq+SMyAFgIf4sMgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkaKpWq9XlvODU1FS0tbUt5yVZ4T7/+c8XPaEhjI+PFz2hIfzzn/8sekJdm56eji1btkS5XI7W1tabnusdDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABS1BSYo0ePRldXV7S2tkZra2t0d3fHq6++mrUNgAZWU2A6Ojri8OHDMTY2FhcuXIjHH388nnrqqXj77bez9gHQoNbUcvLevXtvePz9738/jh49GufPn48vfelLSzoMgMZWU2D+0+zsbPz2t7+NmZmZ6O7u/sTzKpVKVCqV+cdTU1OLvSQADaTmm/yXLl2KO+64I0qlUnzzm9+M4eHh2LJlyyeePzQ0FG1tbfNHZ2fnLQ0GoDHUHJgHHnggxsfH489//nN861vfit7e3vjLX/7yiecPDg5GuVyePyYmJm5pMACNoeaPyJqbm+P++++PiIjt27fH6OhoPP/883Hs2LGPPb9UKkWpVLq1lQA0nFv+PZi5ubkb7rEAQESN72AGBwdjz549sXnz5pieno7jx4/H2bNn49SpU1n7AGhQNQVmcnIynn322fj73/8ebW1t0dXVFadOnYqvfe1rWfsAaFA1BeZnP/tZ1g4AVhh/iwyAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKRYU/QAuFV//etfi57QEJ599tmiJzSEX/7yl0VPqGtNTU0LPtc7GABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkuKXAHD58OJqamuLgwYNLNAeAlWLRgRkdHY1jx45FV1fXUu4BYIVYVGCuXbsWzzzzTPzkJz+JO++8c6k3AbACLCowfX198eSTT0ZPT8//e26lUompqakbDgBWvjW1fsGJEyfi4sWLMTo6uqDzh4aG4nvf+17NwwBobDW9g5mYmIgDBw7Er371q1i7du2CvmZwcDDK5fL8MTExsaihADSWmt7BjI2NxeTkZDz44IPzz83OzsbIyEi88MILUalUYvXq1Td8TalUilKptDRrAWgYNQVm165dcenSpRue27dvX3zxi1+M73znOx+JCwC3r5oC09LSElu3br3hufXr18ddd931kecBuL35TX4AUtT8U2T/7ezZs0swA4CVxjsYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASDFmuW+YLVaXe5LAhFx/fr1oic0hKmpqaIn1LXp6emIWNj38qbqMn/H/9vf/hadnZ3LeUkAltjExER0dHTc9JxlD8zc3Fxcvnw5WlpaoqmpaTkv/Ymmpqais7MzJiYmorW1teg5dclrtDBep4XxOi1MPb5O1Wo1pqeno729PVatuvldlmX/iGzVqlX/b/WK0traWjf/E+uV12hhvE4L43VamHp7ndra2hZ0npv8AKQQGABSCExElEqlOHToUJRKpaKn1C2v0cJ4nRbG67Qwjf46LftNfgBuD97BAJBCYABIITAApBAYAFLc9oE5cuRI3HvvvbF27dp4+OGH48033yx6Ut0ZGRmJvXv3Rnt7ezQ1NcVLL71U9KS6MzQ0FA899FC0tLTExo0b4+mnn45333236Fl15+jRo9HV1TX/i4Pd3d3x6quvFj2r7h0+fDiampri4MGDRU+pyW0dmJMnT8bAwEAcOnQoLl68GNu2bYvdu3fH5ORk0dPqyszMTGzbti2OHDlS9JS6de7cuejr64vz58/H6dOn4/r16/HEE0/EzMxM0dPqSkdHRxw+fDjGxsbiwoUL8fjjj8dTTz0Vb7/9dtHT6tbo6GgcO3Ysurq6ip5Su+ptbOfOndW+vr75x7Ozs9X29vbq0NBQgavqW0RUh4eHi55R9yYnJ6sRUT137lzRU+renXfeWf3pT39a9Iy6ND09Xf3CF75QPX36dPXRRx+tHjhwoOhJNblt38F8+OGHMTY2Fj09PfPPrVq1Knp6euKNN94ocBkrQblcjoiIDRs2FLykfs3OzsaJEydiZmYmuru7i55Tl/r6+uLJJ5+84ftUI1n2P3ZZLz744IOYnZ2NTZs23fD8pk2b4p133iloFSvB3NxcHDx4MB555JHYunVr0XPqzqVLl6K7uzv+9a9/xR133BHDw8OxZcuWomfVnRMnTsTFixdjdHS06CmLdtsGBrL09fXFW2+9FX/605+KnlKXHnjggRgfH49yuRy/+93vore3N86dOycy/2FiYiIOHDgQp0+fjrVr1xY9Z9Fu28DcfffdsXr16rh69eoNz1+9ejXuueeeglbR6Pr7++OVV16JkZGRuv1nKYrW3Nwc999/f0REbN++PUZHR+P555+PY8eOFbysfoyNjcXk5GQ8+OCD88/Nzs7GyMhIvPDCC1GpVGL16tUFLlyY2/YeTHNzc2zfvj3OnDkz/9zc3FycOXPG58HUrFqtRn9/fwwPD8frr78e9913X9GTGsbc3FxUKpWiZ9SVXbt2xaVLl2J8fHz+2LFjRzzzzDMxPj7eEHGJuI3fwUREDAwMRG9vb+zYsSN27twZzz33XMzMzMS+ffuKnlZXrl27Fu+999784/fffz/Gx8djw4YNsXnz5gKX1Y++vr44fvx4vPzyy9HS0hJXrlyJiP/9h5nWrVtX8Lr6MTg4GHv27InNmzfH9PR0HD9+PM6ePRunTp0qelpdaWlp+cj9u/Xr18ddd93VWPf1iv4xtqL96Ec/qm7evLna3Nxc3blzZ/X8+fNFT6o7f/zjH6sR8ZGjt7e36Gl14+Nen4io/uIXvyh6Wl35xje+Uf3c5z5XbW5urn7mM5+p7tq1q/qHP/yh6FkNoRF/TNmf6wcgxW17DwaAXAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkOJ/ADBU38X4ClCmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_t[0, 10:15, 10:15], cmap = 'gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65b4b080",
   "metadata": {},
   "source": [
    "### Traning set-\n",
    "##### used to train the model i.e compute the loss and adjust the weights of the model using gradient descent\n",
    "### Validation set-\n",
    "\n",
    "##### used to evaluate the model while training, adjust hyperparameter (learning rate, e.t.c.) and pick the best version of the model\n",
    "\n",
    "### Test set-\n",
    "##### used to compute different models, or different types of modleing approaches and report the finaccuracy of the model\n",
    "\n",
    "\n",
    "#### there are no predefined validation set, therefore we must manually split the 60,000 images into traing and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8937b9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "# let us define a function that randomly picks a given fraction of the images for the validation set\n",
    "\n",
    "np.set_printoptions(suppress = True)\n",
    "def split_indx(n, val_frct):\n",
    "    n_val = int(n*val_frct)   # no. of images x faction\n",
    "    idx = np.random.permutation(n)   # creating random permutation of 0 to n-1\n",
    "    return idx[n_val:], idx[:n_val]\n",
    "\n",
    "train_idx, val_idx = split_indx(len(dataset), 0.15)\n",
    "print(len(train_idx))\n",
    "print(len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf06dde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.sampler.SubsetRandomSampler object at 0x7f2c34b0b700>\n"
     ]
    }
   ],
   "source": [
    "batch_size=5\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "print(train_sampler)\n",
    "train_loader = DataLoader(dataset, batch_size, sampler=train_sampler)\n",
    "\n",
    "val_sampler = SubsetRandomSampler(val_idx)\n",
    "val_loader = DataLoader(dataset, batch_size, sampler=val_sampler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "819bebb9",
   "metadata": {},
   "source": [
    "since nn.linear expects the each training examples to be a vactor, each 1x28x28 image tensor needs to be flattened out into a vector of size(28x28)\n",
    "\n",
    "the output of ecah image is the vector  of size 10, with each element of the vector signifying the probability of a particular target label(i.e. 0 to 9). the predicted label for an image is simply the one with teh highest probablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fdd4b2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0331,  0.0084, -0.0121,  ..., -0.0040,  0.0304, -0.0135],\n",
      "        [ 0.0180,  0.0218, -0.0198,  ..., -0.0188, -0.0220,  0.0147],\n",
      "        [ 0.0268,  0.0225,  0.0033,  ...,  0.0135,  0.0343,  0.0342],\n",
      "        ...,\n",
      "        [ 0.0043, -0.0016,  0.0193,  ...,  0.0028, -0.0082, -0.0013],\n",
      "        [ 0.0154,  0.0145, -0.0098,  ...,  0.0257,  0.0325,  0.0013],\n",
      "        [-0.0215, -0.0298,  0.0067,  ...,  0.0331, -0.0098, -0.0084]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0129,  0.0051, -0.0131,  0.0343,  0.0131, -0.0276, -0.0054, -0.0239,\n",
      "         0.0293,  0.0246], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress = True)\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "model = nn.Linear(input_size, num_classes)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "120543c9",
   "metadata": {},
   "source": [
    "since our images are of the shape 1x28x28 but we need them to be a vector of size 784 i.e. we need to flatten them out. we will use .reshape method of tensor which will allow us to efficiently view each image as a flat vector. \n",
    "to include this additional functionality within our model, we need to define a custom model by extending the nn.Module class from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "476a5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # to inherit the nn.Module class\n",
    "        self.linear1 = nn.Linear(input_size, 256)\n",
    "        self.linear2 = nn.Linear(256, num_classes)\n",
    "        self.Relu = nn.ReLU()\n",
    "        # print('self.linear= ', self.linear)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        # print('old xb size= ', xb.shape)\n",
    "        # print('old xb= ', xb)\n",
    "        xb = xb.reshape(-1,784)  # -1 allows to work with any batch size\n",
    "        # print('xb size= ', xb.shape)\n",
    "        # print('xb= ', xb)\n",
    "        out = self.linear1(xb)\n",
    "        out = self.linear2(self.Relu(out))\n",
    "        out = self.Relu(out)\n",
    "        return out\n",
    "\n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77a2623c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 7, 9, 8, 0])\n",
      "torch.Size([5, 1, 28, 28])\n",
      "otpt size= torch.Size([5, 10])\n",
      "tensor([[0.0641, 0.0435, 0.0409, 0.0000, 0.0000, 0.1046, 0.0000, 0.0000, 0.0297,\n",
      "         0.0000],\n",
      "        [0.1357, 0.0000, 0.2089, 0.0000, 0.0144, 0.0000, 0.0000, 0.0000, 0.0197,\n",
      "         0.0608],\n",
      "        [0.0000, 0.0000, 0.0957, 0.0000, 0.0238, 0.0248, 0.0000, 0.0000, 0.0693,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0890, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0578,\n",
      "         0.0000],\n",
      "        [0.0390, 0.0000, 0.0167, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0087,\n",
      "         0.0000]], grad_fn=<ReluBackward0>)\n",
      "torch.Size([256, 784])\n",
      "torch.Size([256])\n",
      "torch.Size([10, 256])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(labels)\n",
    "    print(images.shape)\n",
    "    otpt = model(images)\n",
    "    print('otpt size=', otpt.shape)\n",
    "    print(otpt)\n",
    "    break\n",
    "print(model.linear1.weight.shape)\n",
    "print(model.linear1.bias.shape)\n",
    "print(model.linear2.weight.shape)\n",
    "print(model.linear2.bias.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25359eb9",
   "metadata": {},
   "source": [
    "now we want to convert the each data value in the weigth as probabilities and therefore the values should be in range[0,1] and sum of all the probabilties should add to 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c68a9700",
   "metadata": {},
   "source": [
    "to do so we first raise all the values(vi) in the row to e^(vi). this is to make a significant difference between the numbers. then we divide the value by sum of all the elements. the value we got is called the softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2172b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1036, 0.1015, 0.1012, 0.0972, 0.0972, 0.1079, 0.0972, 0.0972, 0.1001,\n",
      "         0.0972],\n",
      "        [0.1093, 0.0955, 0.1176, 0.0955, 0.0969, 0.0955, 0.0955, 0.0955, 0.0974,\n",
      "         0.1014],\n",
      "        [0.0978, 0.0978, 0.1077, 0.0978, 0.1002, 0.1003, 0.0978, 0.0978, 0.1049,\n",
      "         0.0978],\n",
      "        [0.0985, 0.0985, 0.1077, 0.0985, 0.0985, 0.0985, 0.0985, 0.0985, 0.1044,\n",
      "         0.0985],\n",
      "        [0.1033, 0.0994, 0.1010, 0.0994, 0.0994, 0.0994, 0.0994, 0.0994, 0.1002,\n",
      "         0.0994]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "prob = F.softmax(otpt, dim=1)\n",
    "print(prob)\n",
    "print(prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9b0a1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1079, 0.1176, 0.1077, 0.1077, 0.1033], grad_fn=<MaxBackward0>)\n",
      "torch.Size([5])\n",
      "tensor([5, 2, 2, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "max_prob, pred = torch.max(prob, dim=1)\n",
    "print(max_prob)\n",
    "print(max_prob.shape)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc29cf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 7, 9, 8, 0])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f734d84a",
   "metadata": {},
   "source": [
    "# Evaluation matrix and Loss function\n",
    "#### just as with linear regression, we need a way to evaluate how well our model is performing. A natural way to do is to find the percentage of lables that were predicted correctly i.e. the accuracy of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f483c4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(l1, l2):\n",
    "    return torch.sum(l1==l2).item()/len(l1)\n",
    "\n",
    "accuracy(pred, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c347f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False,  True])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels==pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5f2b4e8",
   "metadata": {},
   "source": [
    "##### we can not use accuracy as our loss function, because accuray is non continous and differentiable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86c411a4",
   "metadata": {},
   "source": [
    "##### a commonly used loss fnx for clarrification problem is the cross entropy which can be done in the following way"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ab9a54e",
   "metadata": {},
   "source": [
    "##### for each output row pick the predicted probability for the correct label.\n",
    "\n",
    "##### then take the log of the picked value. if the probability is high or close to 1 then the log value will be very small negative value close to zero. if the probabilty is close to one then the log value will be very high negative value. so we multiply the value with -1 which makes it positive\n",
    "\n",
    "##### then take the avg value of the entory across all the output row to get the overall loss for the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7a79db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3030, grad_fn=<NllLossBackward0>)\n",
      "tensor([3, 7, 9, 8, 0])\n"
     ]
    }
   ],
   "source": [
    "loss_fn = F.cross_entropy\n",
    "loss = loss_fn(prob, labels)\n",
    "print(loss)\n",
    "print(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "667a89aa",
   "metadata": {},
   "source": [
    "# Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc433873",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_r = 0.001\n",
    "opt = torch.optim.SGD(model.parameters(), lr=l_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bfc61a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_fxn, xb, yb, opt=None, metric=None):\n",
    "    preds = model(xb)   # find the predictions by putting the batch into the model fxn\n",
    "    loss = loss_fxn(preds, yb) # then find the loss wrt to the lables provided\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()   # compute gradient\n",
    "        opt.step()        # update parameters\n",
    "        opt.zero_grad()   # reset gradients\n",
    "    \n",
    "    metric_result = None\n",
    "    if metric is not None:\n",
    "        metric_result = metric(preds, yb)\n",
    "    \n",
    "    return loss.item(), len(xb), metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "588c7c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, loss_fn, valid_dl, metric=None):\n",
    "    with torch.no_grad():\n",
    "        # for loop gives the batches out of the validation set\n",
    "        # metric is the accuracy matrix\n",
    "        results = [loss_batch(model, loss_fn, xb, yb, metric=metric)\n",
    "                  for xb, yb in valid_dl]\n",
    "        # to separate out the lists we use zip function\n",
    "        losses, nums, metrics = zip(*results)\n",
    "        # total size is the sum of all the batch size\n",
    "        total = np.sum(nums)\n",
    "        # since we have divded the set into batches therefore we can have the last batch size to be smaller than the rest\n",
    "        # so we first calculate the length and then find its avg value\n",
    "        # suppose we have a batch of size 3, 3 and 2. so we take the first loss and multipy with 3, take 2nd and multiply with \n",
    "        # 3 and then take 3rd loss and muliply with 2. ten sum all the values and then divide by sum of batch size i.e. 3+3+2\n",
    "        avg_loss = np.sum(np.multiply(losses, nums)) / total\n",
    "        avg_metric = None\n",
    "        if metric is not None:\n",
    "            avg_metric = np.sum(np.multiply(metrics, nums))/total\n",
    "        return avg_loss, total, avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "09efbcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, lables):\n",
    "    prob, preds = torch.max(outputs, dim = 1)\n",
    "    return torch.sum(preds == lables).item()/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b73968c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_fn, opt, train_dl, valid_dl, metric=None):\n",
    "    for i in range(epochs):\n",
    "        # Training\n",
    "        for xb, yb in train_dl:\n",
    "            loss, length, metric_result = loss_batch(model, loss_fn, xb, yb, opt)\n",
    "        \n",
    "        # Evaluation\n",
    "        result = evaluation(model, loss_fn, valid_dl, metric)\n",
    "        val_loss, total, val_metric = result\n",
    "        \n",
    "        # printing the progress\n",
    "        if metric is None:\n",
    "            print(\"epoch [\", i+1, ',', epochs, '] , loss= ', val_loss)\n",
    "        else:\n",
    "            print('*Epoch [', i+1, ',', epochs, '], loss= ', val_loss, ',', metric.__name__, ',' , val_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ea3ad585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "52074732",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "train_dl = DeviceDataLoader(train_loader, device)\n",
    "val_dl = DeviceDataLoader(val_loader, device)\n",
    "model = MnistModel()\n",
    "to_device(model, device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= l_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c5be3994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Epoch [ 1 , 100 ], loss=  0.8624865623687704 , accuracy , 0.7586666666666667\n",
      "*Epoch [ 2 , 100 ], loss=  0.6774466987306045 , accuracy , 0.784\n",
      "*Epoch [ 3 , 100 ], loss=  0.6182285292343133 , accuracy , 0.7944444444444444\n",
      "*Epoch [ 4 , 100 ], loss=  0.5875305208995835 , accuracy , 0.8003333333333333\n",
      "*Epoch [ 5 , 100 ], loss=  0.33310868731208354 , accuracy , 0.9054444444444445\n",
      "*Epoch [ 6 , 100 ], loss=  0.3089985283227482 , accuracy , 0.9117777777777778\n",
      "*Epoch [ 7 , 100 ], loss=  0.29354071368618556 , accuracy , 0.9154444444444444\n",
      "*Epoch [ 8 , 100 ], loss=  0.28028896859730595 , accuracy , 0.921\n",
      "*Epoch [ 9 , 100 ], loss=  0.2678345639727518 , accuracy , 0.925\n",
      "*Epoch [ 10 , 100 ], loss=  0.2577518411774913 , accuracy , 0.9272222222222222\n",
      "*Epoch [ 11 , 100 ], loss=  0.24990487878417803 , accuracy , 0.9296666666666666\n",
      "*Epoch [ 12 , 100 ], loss=  0.24179982794151228 , accuracy , 0.9314444444444444\n",
      "*Epoch [ 13 , 100 ], loss=  0.2335400431427277 , accuracy , 0.934\n",
      "*Epoch [ 14 , 100 ], loss=  0.22603568199368762 , accuracy , 0.9355555555555556\n",
      "*Epoch [ 15 , 100 ], loss=  0.22048463748716232 , accuracy , 0.9357777777777778\n",
      "*Epoch [ 16 , 100 ], loss=  0.21375389268450412 , accuracy , 0.9378888888888889\n",
      "*Epoch [ 17 , 100 ], loss=  0.2087542925929625 , accuracy , 0.9404444444444444\n",
      "*Epoch [ 18 , 100 ], loss=  0.2027053490070264 , accuracy , 0.9402222222222222\n",
      "*Epoch [ 19 , 100 ], loss=  0.19755469461566666 , accuracy , 0.9413333333333334\n",
      "*Epoch [ 20 , 100 ], loss=  0.19232941602718912 , accuracy , 0.9428888888888889\n",
      "*Epoch [ 21 , 100 ], loss=  0.1879079389332522 , accuracy , 0.9436666666666667\n",
      "*Epoch [ 22 , 100 ], loss=  0.18371067242383207 , accuracy , 0.9453333333333334\n",
      "*Epoch [ 23 , 100 ], loss=  0.17930834089302355 , accuracy , 0.9467777777777778\n",
      "*Epoch [ 24 , 100 ], loss=  0.1758006041854646 , accuracy , 0.9481111111111111\n",
      "*Epoch [ 25 , 100 ], loss=  0.17240148203392489 , accuracy , 0.9472222222222222\n",
      "*Epoch [ 26 , 100 ], loss=  0.16796270115184597 , accuracy , 0.9501111111111111\n",
      "*Epoch [ 27 , 100 ], loss=  0.16510753674173934 , accuracy , 0.9506666666666667\n",
      "*Epoch [ 28 , 100 ], loss=  0.1621150653882392 , accuracy , 0.951\n",
      "*Epoch [ 29 , 100 ], loss=  0.16028462017234738 , accuracy , 0.9505555555555556\n",
      "*Epoch [ 30 , 100 ], loss=  0.15646195748701253 , accuracy , 0.9528888888888889\n",
      "*Epoch [ 31 , 100 ], loss=  0.1544006379326715 , accuracy , 0.9531111111111111\n",
      "*Epoch [ 32 , 100 ], loss=  0.15099090950743024 , accuracy , 0.955\n",
      "*Epoch [ 33 , 100 ], loss=  0.14835284142997504 , accuracy , 0.9558888888888889\n",
      "*Epoch [ 34 , 100 ], loss=  0.14675186875842175 , accuracy , 0.9555555555555556\n",
      "*Epoch [ 35 , 100 ], loss=  0.14381942465605485 , accuracy , 0.9574444444444444\n",
      "*Epoch [ 36 , 100 ], loss=  0.14248455352398903 , accuracy , 0.9576666666666667\n",
      "*Epoch [ 37 , 100 ], loss=  0.1400082632694264 , accuracy , 0.9577777777777777\n",
      "*Epoch [ 38 , 100 ], loss=  0.13789799848823653 , accuracy , 0.9591111111111111\n",
      "*Epoch [ 39 , 100 ], loss=  0.13632113022361106 , accuracy , 0.9591111111111111\n",
      "*Epoch [ 40 , 100 ], loss=  0.13455341240864882 , accuracy , 0.9588888888888889\n",
      "*Epoch [ 41 , 100 ], loss=  0.1329473746981239 , accuracy , 0.9605555555555556\n",
      "*Epoch [ 42 , 100 ], loss=  0.1315667191206497 , accuracy , 0.9615555555555556\n",
      "*Epoch [ 43 , 100 ], loss=  0.12984979635419827 , accuracy , 0.9617777777777777\n",
      "*Epoch [ 44 , 100 ], loss=  0.12868929047331523 , accuracy , 0.9616666666666667\n",
      "*Epoch [ 45 , 100 ], loss=  0.12694665795091875 , accuracy , 0.9626666666666667\n",
      "*Epoch [ 46 , 100 ], loss=  0.12622607109149006 , accuracy , 0.9631111111111111\n",
      "*Epoch [ 47 , 100 ], loss=  0.12445460615441133 , accuracy , 0.9633333333333334\n",
      "*Epoch [ 48 , 100 ], loss=  0.12282876995421248 , accuracy , 0.9632222222222222\n",
      "*Epoch [ 49 , 100 ], loss=  0.12268214244210361 , accuracy , 0.9638888888888889\n",
      "*Epoch [ 50 , 100 ], loss=  0.12077430514008382 , accuracy , 0.964\n",
      "*Epoch [ 51 , 100 ], loss=  0.11959534488844736 , accuracy , 0.9653333333333334\n",
      "*Epoch [ 52 , 100 ], loss=  0.11812888064436265 , accuracy , 0.9648888888888889\n",
      "*Epoch [ 53 , 100 ], loss=  0.11709631107982002 , accuracy , 0.9655555555555555\n",
      "*Epoch [ 54 , 100 ], loss=  0.11658804153793931 , accuracy , 0.9662222222222222\n",
      "*Epoch [ 55 , 100 ], loss=  0.11501399715197395 , accuracy , 0.9656666666666667\n",
      "*Epoch [ 56 , 100 ], loss=  0.11454184441041636 , accuracy , 0.9663333333333334\n",
      "*Epoch [ 57 , 100 ], loss=  0.11316092149880003 , accuracy , 0.9666666666666667\n",
      "*Epoch [ 58 , 100 ], loss=  0.11270697945387737 , accuracy , 0.9668888888888889\n",
      "*Epoch [ 59 , 100 ], loss=  0.11192879175763261 , accuracy , 0.966\n",
      "*Epoch [ 60 , 100 ], loss=  0.11127276809769683 , accuracy , 0.9664444444444444\n",
      "*Epoch [ 61 , 100 ], loss=  0.11007750394097658 , accuracy , 0.9675555555555555\n",
      "*Epoch [ 62 , 100 ], loss=  0.10992573882192826 , accuracy , 0.9678888888888889\n",
      "*Epoch [ 63 , 100 ], loss=  0.108267423772971 , accuracy , 0.9677777777777777\n",
      "*Epoch [ 64 , 100 ], loss=  0.10863804023138073 , accuracy , 0.9675555555555555\n",
      "*Epoch [ 65 , 100 ], loss=  0.10718964845576313 , accuracy , 0.9682222222222222\n",
      "*Epoch [ 66 , 100 ], loss=  0.10622439365587828 , accuracy , 0.9692222222222222\n",
      "*Epoch [ 67 , 100 ], loss=  0.10626197419521001 , accuracy , 0.9687777777777777\n",
      "*Epoch [ 68 , 100 ], loss=  0.10508806771891412 , accuracy , 0.968\n",
      "*Epoch [ 69 , 100 ], loss=  0.10389207782973649 , accuracy , 0.9682222222222222\n",
      "*Epoch [ 70 , 100 ], loss=  0.10380588547804412 , accuracy , 0.9687777777777777\n",
      "*Epoch [ 71 , 100 ], loss=  0.10352562759808481 , accuracy , 0.9684444444444444\n",
      "*Epoch [ 72 , 100 ], loss=  0.10221610866731579 , accuracy , 0.9693333333333334\n",
      "*Epoch [ 73 , 100 ], loss=  0.10150470587800454 , accuracy , 0.9701111111111111\n",
      "*Epoch [ 74 , 100 ], loss=  0.10194902069105916 , accuracy , 0.9698888888888889\n",
      "*Epoch [ 75 , 100 ], loss=  0.10065298613826194 , accuracy , 0.9701111111111111\n",
      "*Epoch [ 76 , 100 ], loss=  0.10126171621633047 , accuracy , 0.9695555555555555\n",
      "*Epoch [ 77 , 100 ], loss=  0.10003108329275467 , accuracy , 0.9707777777777777\n",
      "*Epoch [ 78 , 100 ], loss=  0.0998963300753773 , accuracy , 0.9705555555555555\n",
      "*Epoch [ 79 , 100 ], loss=  0.0993425503942328 , accuracy , 0.9696666666666667\n",
      "*Epoch [ 80 , 100 ], loss=  0.09872703947684688 , accuracy , 0.9693333333333334\n",
      "*Epoch [ 81 , 100 ], loss=  0.09835699022552893 , accuracy , 0.9708888888888889\n",
      "*Epoch [ 82 , 100 ], loss=  0.09766452840614673 , accuracy , 0.9706666666666667\n",
      "*Epoch [ 83 , 100 ], loss=  0.09799791446697377 , accuracy , 0.9701111111111111\n",
      "*Epoch [ 84 , 100 ], loss=  0.09741366941075992 , accuracy , 0.9702222222222222\n",
      "*Epoch [ 85 , 100 ], loss=  0.0978628338906775 , accuracy , 0.9702222222222222\n",
      "*Epoch [ 86 , 100 ], loss=  0.09660614239274663 , accuracy , 0.9712222222222222\n",
      "*Epoch [ 87 , 100 ], loss=  0.0958240399853235 , accuracy , 0.9705555555555555\n",
      "*Epoch [ 88 , 100 ], loss=  0.09573829761082582 , accuracy , 0.9714444444444444\n",
      "*Epoch [ 89 , 100 ], loss=  0.0954614289076643 , accuracy , 0.9722222222222222\n",
      "*Epoch [ 90 , 100 ], loss=  0.09563091011264381 , accuracy , 0.9705555555555555\n",
      "*Epoch [ 91 , 100 ], loss=  0.09446106516666784 , accuracy , 0.9718888888888889\n",
      "*Epoch [ 92 , 100 ], loss=  0.09504548703530014 , accuracy , 0.9716666666666667\n",
      "*Epoch [ 93 , 100 ], loss=  0.09422641478520948 , accuracy , 0.9714444444444444\n",
      "*Epoch [ 94 , 100 ], loss=  0.09360301896599493 , accuracy , 0.9715555555555555\n",
      "*Epoch [ 95 , 100 ], loss=  0.09393257539708834 , accuracy , 0.9716666666666667\n",
      "*Epoch [ 96 , 100 ], loss=  0.09346582053273678 , accuracy , 0.9718888888888889\n",
      "*Epoch [ 97 , 100 ], loss=  0.09346582351673634 , accuracy , 0.9712222222222222\n",
      "*Epoch [ 98 , 100 ], loss=  0.09229618015877551 , accuracy , 0.972\n",
      "*Epoch [ 99 , 100 ], loss=  0.09257981251283834 , accuracy , 0.9715555555555555\n",
      "*Epoch [ 100 , 100 ], loss=  0.0923498297693752 , accuracy , 0.972\n"
     ]
    }
   ],
   "source": [
    "fit(100, model, F.cross_entropy, optimizer, train_dl, val_dl, accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fd2097b",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "66eb87b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=  torch.Size([1, 28, 28])\n",
      "label=  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = MNIST(root = \"/media/souravsaini/Data/POP_OS/dl/pytorch/pytorch\", train = False, transform=trn.ToTensor())\n",
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap = 'gray')\n",
    "print('shape= ', img.shape)\n",
    "print('label= ', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6088b948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "be9be623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    prob, pred = torch.max(yb, dim=1)\n",
    "    return pred[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f881271a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=  0.07892555457764525  accuracy=  0.9748\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=5)\n",
    "test_loader = DeviceDataLoader(test_loader, device)\n",
    "test_loss, total, test_acc = evaluation(model, loss_fn, test_loader, accuracy)\n",
    "print('Loss= ', test_loss, \" accuracy= \", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
